1 Example C++ memory safety example (CWE top 25)
2 Origin of Rust (mozilla 2015, servo & multithreaded firefox)
3 Linear typesystem, ownership, borrowing (scope, lifetime)
4 Enums
5 Error handling (return types vs. C++ exception)
6 Polymorphism (Generics, traits and trait objects)
7 Concurrency (send&sync, Arcs, mutex)
8 Unsafe
9 Macros
10 Modules
11 Integrated tests & benchmark
12 Std::lib
13 Cargo
14 Releases & development

We explain syntax at each example

0. Introduction
------------------

... intro Erdem ...

My name is Micha Hergarden and I am part of the SICS team at EUV source. I have a background in Software Engineering with about 20 years of experience. I came into contact with Rust at the 2015 Fosdem software conference and got to use it for my thesis in 2018.

Our aim for tonight is to give you a short tour of the Rust programming language and to show in what aspects it differs from its cousins c and c++.

1. Example C++ memory safety
------------------

#include<iostream>
#include<vector>
#include<string>

int main(int argc, char *argv[])
{
        std::vector<std::string> strings;

        strings.push_back("Hello");
        strings.push_back("World");

        std::string& ref = strings[0];

	add_more_strings(&strings);

        std::cout << ref << std::endl;
        return 0;
}

Will this work? The answer is: maybe. In some cases the vector will allocate new memory to enlarge and move its elements to this newly allocated block. The problem is that the reference 'ref' is then pointing into unused memory. This opens the door for segmentation faults or information leaking.

The CWE website tracks common weaknesses in software development (https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html). The top 25 shows numerous issues that may arise in software where memory management is not done properly. An internal investigation at Microsoft also showed that about 70% of the security bugs found in their products are related to memory management (https://cwe.mitre.org/top25/archive/2020/2020_cwe_top25.html). The Chromium project reports the same figures for their Chrome derived browser ( https://www.chromium.org/Home/chromium-security/memory-safety).

This seems to suggest that even with good engineers working on the code, it is still difficult to prevent these types of errors from occuring. A common denominator for these issues is the use of languages like C or C++. These languages offer runtime efficiency and low level control, but have the trade off of requiring rigorous testing and code checking to make sure no unintended issues are introduced. In contrast, languages with a garbage collector offer better protection from some of these types of issues but have the trade off of lacking the low level control needed in certain application domains, i.e. realtime systems. Enter Rust...

2. Origin of Rust
------------------

In 2006 a Mozilla Research employee named Graydon Hoare started the Rust language project as a means to design a language that provides better memory safety guarantees while still offering the low level control that c and c++ offer. Mozilla started sponsoring the project in 2009 and announced it in 2010. The first major release of the language was in 2015. Initially the language was used for the Servo browser project. Servo was developed in cooperation with Samsung as a means to explore the concurrency and memory safety properties of Rust in order to create a parallelized web browser. The CSS style engine has already found its way into the Firefox browser.

Rust gained popularity outside of Mozilla and has earned the honour of being the "most loved programming language" on the Stack Overflow developer survey since 2016. The industry also started adopting the language and according to the project page around 148 companies are using Rust in production code. Microsoft and Google have shown serious interest and researched the language for use in security critical components.

3. Linear typesystem, ownership, borrowing and lifetimes. (take image from thesis)
------------------

The main property that differentiates Rust from languages like C and C++ is its typesystem. This system is known as a linear typesystem. The book 'Advanced topics in Types and Programming Languages' by Benjamin Pierce defines a linear typesystem as follows:

"Linear type systems ensure that every variable is used exactly once by allowing exchange but not weakening or contraction."

The key words here are 'used exactly once'. In this context this means that data in a certain memory region representing an object can be associated with one name only. To clarify this further I will explain this in terms of a c++ string object. In c++ a string is represented by two structures. First a structure that is associated with the string variable name. This structure contains a pointer to the second structure, a length and a capacity. The length is the number of characters in the string data, and the capacity is the maximum number of characters that can be held in the string data. The pointer points to the actual characters that make up the string and are stored in the heap.

In c++ you can make a shallow copy, meaning that you create a copy of the first struct and associate that with a different name. The pointer to the heap data is identical to the first string object. The advantage of that is that you do not need to copy a potentially large amount of heap data. The drawback is that the administration in both variables need to be kept in sync. In a linear typesystem, this is considered double use and thus prohibited. When a new variable is associated with the data, the initial struct is marked 'invalid'. Any attempt to access the data via the first variable will result in a compile time error. This concept is called 'Ownership' and can be compared to a person owning a physical object like a book.

To summarize: at any given time, a value must have an owner and can have only one owner. When the owner is destroyed, the value is also destroyed.

In Rust it is possible to associate a second variable name to the string by means of a reference. The reference contains then a pointer to the first variable, which in turn points to the actual string data. This referencing mechanism is called 'Borrowing' and can be compared to a person lending a book to a friend. The friend may read the book, as long as the book is returned to the owner in due time. By default, a reference is immutable. Any attempt to modify the value through a reference will lead to a compile time error. A refence can explicitly be made mutable, but then there can only be a single reference.

To summarize: at any given time there may be many immutable references to a value or a single mutable reference. A reference must always be valid.

Let's view this in a piece of Rust code.

In the first example we pass a string value to a function that will uppercase it internally. The function takes the string by value and therefore the ownership of the string is transferred to the function (or rather the variable name in the argument). 

fn uppercase(input: String) {
    input.to_uppercase();
}

fn main() {
    let output = String::from("hello world.");
    uppercase(output);
}

Any attempt to refer to the string after calling the function will result in a compilation error:

fn uppercase(input: String) {
    input.to_uppercase();
}

fn main() {
    let output = String::from("hello world.");
    uppercase(output);
    //print!("{}", output);
}

The output from the compiler is:

micha@linux-gvwr:~/asml-tour-of-rust/ownership (main)> cargo run
   Compiling ownership v0.1.0 (/home/micha/asml-tour-of-rust/ownership)
error[E0382]: borrow of moved value: `output`
 --> src/main.rs:8:18
  |
6 |     let output = String::from("hello world.");
  |         ------ move occurs because `output` has type `std::string::String`, which does not implement the `Copy` trait
7 |     uppercase(output);
  |               ------ value moved here
8 |     print!("{}", output);
  |                  ^^^^^^ value borrowed here after move

error: aborting due to previous error

For more information about this error, try `rustc --explain E0382`.
error: could not compile `ownership`.

To learn more, run the command again with --verbose.

When we pass the same string by reference, the ownership is not transferred but the function is able to borrow the string. The main function can still use the string after the function returns:

fn uppercase(input: &String) {
    input.to_uppercase();
}

fn main() {
    let output = String::from("hello world.");
    uppercase(&output);
    print!("{}", output);
}

A nice consequence of using linear types is that there is no need for a garbage collector. The compiler can deduce which variable a value belongs to and what the scope of that variable is. In Rust this scope is called the Lifetime of a variable. The absence of a garbage collector lets Rust enter the domain of languages like c and c++ and this is why it is often touted as a system programming language. In the event that you really do need a copy of a value, you can create one by calling the 'clone()' method on a type. This creates a deep copy of the value.

4. Enums
------------------

----- ERDEM ----------

5. Error Handling (Don't panic!)
------------------

Rust divides error handling in two categories: non-recoverable and recoverable. A non-recoverable error is an condition in the program that should never happen and is cause for the program to end prematurely. An example of that would be a division by zero as that leads to an undefined result. In Rust such an error is called a 'panic'. In the event of a panic, the program halts and a default handler is called. Rust will start unwinding the stack and print out a stacktrace for further analysis. One thing to note is that a panic will stay within the boundaries of a thread. So if one thread panics, it does not mean that your whole program will crash. Instead, the thread will abort and the parent thread will be able to retrieve a thread result. In this case the result will be an error. This makes for more robust programs and allows the program to continue the other threads.

An example of a panic situation happens for instance when we explicitly call the panic macro:
fn do_something() {
    panic!("Oh noes!");
}

fn main() {
    do_something();
}

micha@linux-gvwr:~/asml-tour-of-rust/panic (main)> cargo run
   Compiling panic v0.1.0 (/home/micha/asml-tour-of-rust/panic)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/panic`
thread 'main' panicked at 'Oh noes!', src/main.rs:2:5
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

When the program us run with the RUST_BACKTRACE variable set, we will see a full backtrace, including the panic handler itself. In a lot of cases, the output from the less verbose panic is clear enough to deduce what caused the program to terminate. And when the panic macro is used, the programmer often provides an explicit error message to be printed out.

Let's move on to recoverable errors. The Rust language does not have an exception mechanism. Instead it relies on return values. The advantage of using these values is that the caller must do something with them. It is not possible to ignore the error by accident.

Rust has two enum types to denote error conditions:

enum Result<T,E> {
	Ok(T),
	Err(E),
}

The Result enum contains either the value of Ok, which can contain a result type, which should be the result of the function. It also contains a type for the Error case, which is used to attach information about the error. Let's look at an example of its use:

use std::fs::File;

fn main() {
    let f = File::open("hello.txt");

    let f = match f {
        Ok(file) => file,
        Err(error) => panic!("Problem opening the file: {:?}", error),
    };
}

Here we use a so called match operator to distinguish between the good case and the error case. In the event of an error we turn it into a panic and print out the error. Here is the output in the event of a missing file:

thread 'main' panicked at 'Problem opening the file: Os { code: 2, kind: NotFound, message: "No such file or directory" }', src/main.rs:8:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace

As we can see here the error has a kind and a message to convey additional information about what happened. The match statement above is still a bit verbose, so it is possible to write a shorthand for that using the available methods in the Result type:

let x = get_weather("Veldhoven").or(Ok(default));

In this case we get a weather report for Veldhoven if all goes well, or we get a result containing a default report in case of a failure. The result type contains more functions to tweak the error case, such as returning a value instead of a result, calling a function in the event of an error to produce a default and producing a mutable value. Have look at the reference documentation if you are interested in this topic.

An alternative to the Result type is the option type. This is used when it is ok when there might not be a value to return. Instead of returning a NULL which could go unchecked by the caller, the Option type must be handled. This forces the caller to expect this case as well.

enum Option<T> {
	Some(T),
	None
}

6. Polymorphism
------------------

Polymorphism in Rust is enabled by the use of Traits, which are similar to Interfaces in Java or Abstract classed in C++. Rust does not have classes or inheritance, but you can create structs and add methods to them by implementing a trait which declares the methods. An example of a trait and implementation would be creating a number of animals:

trait Sound {
	fn make_noise(&Self)-> String;
}

A dog and cat could then implement this trait as follows:

struct Dog { name: String };

impl Sound for Dog {
	fn make_noise(&Self) -> String {
		return String::from("Woof!");
	}
}

struct Cat { name: String };

impl Sound for Cat {
	fn make_noise(&Self) -> String {
		return String::from("Meow!");
	}
}

Here we define the trait Sound, which can be implemented to give a dog or a cat the ability to make a sound. Traits resemble abilities and represent something that a type can do. In Rust you must have a trait in your scope in order to implement its methods. The reason for this is that it could lead to naming conflicts otherwise. We will see later how a trait can be brought into scope in the section on modules. A nice feature of this system is that it allows you to even extend build in types like an int 32 with your own traits.

Trait objects

Because Rust does not have classes or inheritance, you cannot create base classes. Suppose I want to create a framework for gui elements. Each element should be able to draw itself, so we define a Draw trait that must be implemented by the elements:

trait Draw {
	fn draw(&self);
}

If we want to make a canvas with a vector of different elements we cannot do this:

struct Canvas {
	canvas: Vec<Draw>,
}

The reason is that Rust wants to know the size of the elements at compile time and some elements might not even be known by then, for instance if we offer this as a library that may be extended by others. The way Rust solves this is by means of a trait object. A trait object is an object that contains at least two pointers: one pointing to the concrete type implementing the trait and one to the vtable that contains pointers to implementations of the trait.
This is denoted in Rust as follows:

struct Canvas {
	canvas: Vec<Box<dyn Draw>>,
}

Here we use a Box, which is a smart pointer which will be converted to a trait object. The dyn keyword tells Rust that we are talking about a trait instead of a struct type. In this way we can store many types of elements in the canvas. And trait objects allow us to extend an existing type with multiple vtables, i.e. implement multiple traits.

Generic functions

One other way to achieve polymorphism is the use of generic functions. Generic functions are similar to using templates in C++. Suppose we want to define a min function, which returns the smallest of two values. We could implement it like so:

fn min(value1: u32, value2: u32) -> u32 {
	if value1 <= value2 {
		value1
	} else {
		value2
	}
}

This of course only works for u32 types, so we want to make it more generic:

fn min<T>(value1: T, value2: T) -> T {
	if value1 <= value2 {
		value1
	} else {
		value2
	}
}

The capital T denotes any type with which this function will be called. Like templates, Rust will generate the machine code compile time for each type. There is still one problem with this implementation however. Not all types can be compared. So we need to add some sort of restriction on the type that can be used. Such a restriction is called a bound in Rust and can be added like so:

fn min<T: Ord>(value1: T, value2: T) -> T {
	if value1 <= value2 {
		value1
	} else {
		value2
	}
}

Now only the right types can be used with this function. It is possible to add more generic types and it is also possible to add more bounds to a type. We will not be diving deeper into this topic for now.

It can be tricky to decide when to use trait objects and when to use generics. Generics may cause code bloat, because there will be code generated for each type the function is called with. And the generated code may be inlined. The upshot however is that there is practically no runtime overhead. This is in contrast with trait objects, which do have some indirection overhead at runtime, but will produce no code bloat.

7. Concurrency
------------------

The strength of the linear typesystem lies in its application in concurrent programming. Concurrent programming has numerous pitfalls such as data races where multiple threads mutate the same value in memory at interleaved execution, deadlocks and livelocks. These pitfalls only come into play when you have shared mutable state. The common solution to this is to remove mutability by adding locks like mutexes. Rust however tries to solve this by removing the shared part. Let's first look at the paradigms that Rust supports.

Fork/Join

The simplest concurrent model that we can implement is having multiple threads that do not share data. Here is an example of such a program:

fn proces_files(files: Vec<String>) -> io::Result<()> {
	const NTHREADS: usize = 8;

	// Break up the vector in multiple blocks
	let worklists = split_vec_into_chunks(files, NTHREADS);

	let mut thread_handles = vec![];

	for worklist in worklists {
		thread_handles.push(
				spawn(move || process_files(worklist))
				);
	};

	for handle in thread_handles {
		handle.join().unwrap()?;
	}
}

There a few things to unpack here, so let's go through them one by one. The return value of this function is an io::Result value. The functions starts by splitting up a vector in multiple blocks so that each thread can work on its own block. We then create an empty vector of handles, using a macro. More on macros later on in the presentation. We then loop through the list of lists and create a thread for each one using the spawn method. The argument of this method is the keyword 'move' to indicate a transfer of ownership of a worklist to the thread. This is followed by a closure, denoted by the pipe symbols. A closure is a lightweight function where the pipe symbols surround the arguments (none in this case), followed by the body, which is processing the actual list.
Finally we loop through the list of handles and wait for each thread to finish before continuing. The question mark operator helps propagating a possible io::Result to the parent thread.

This type of parallellism is fairly easy to follow, but it does have the possibility of an unequal load balance in the threads. For instance, the proces_files maybe slow on large files. A thread with a worklist containing only large files will then be slower to finish than a thread with small files. This could leave one thread finishing early while it could help the other thread out.

One thing to note is that if we would handle the io::Result here, the program as a whole would not panic in the event of a single thread panic. This allows the main program to collect results even if one thread would fail to do so. In this case the error is explicitly propagated and thus the whole program would panic.

Sharing immutable data

Now suppose we want to process the files using some shared configration file. We could extend the proces_files function with a reference to this file:

fn process_files(worklist: Vec<String>, config: &Configuration){
	const NTHREADS: usize = 8;

	// Break up the vector in multiple blocks
	let worklists = split_vec_into_chunks(files, NTHREADS);

	let mut thread_handles = vec![];

	for worklist in worklists {
		thread_handles.push(
				spawn(move || process_files(worklist, configuration))
				);
	};

	for handle in thread_handles {
		handle.join().unwrap()?;
	}
}

This will not compile, because we try to move ownership in the spawn call, and we cannot transfer ownership of a referenced object. The reason for this is that each thread will have its own independent lifetime. To Rust there is no guarantee that the child will never outlive its parent thread. It therefore assumes the worst and forbids sharing a reference in this way.

The solution to this is to use a so called Arc, Atomic Reference Count.

use std::sync::Arc;

fn process_files(worklist: Vec<String>, config: Arc<Configuration>){
	const NTHREADS: usize = 8;

	// Break up the vector in multiple blocks
	let worklists = split_vec_into_chunks(files, NTHREADS);

	let mut thread_handles = vec![];

	for worklist in worklists {
		let config_for_child = config.clone();

		thread_handles.push(
				spawn(move || process_files(worklist, &config_for_child))
				);
	};

	for handle in thread_handles {
		handle.join().unwrap()?;
	}
}

First we import the Arc type from the sync module by means of the use statement. The configuration is then wrapped in an Arc. We create a clone of the Arc for each child thread. The clone increments the reference count in an atomic thread safe manner. Each thread will receive the cloned arc and is able to read from the configuration. The Configuration object can only be destroyed when the reference count is set to zero, which can only happen when all threads have finished. So even if the parent would bail out first, the childs will still have access to the configuration.

Because the configuration is immutable, there won't be any data races. Childs can only read from the config.

There exist libraries to simplify working with spawn/join. Examples are Crossbeam and Rayon. We will not dive into them here.

Channels

Another way of sharing data between threads is with the use of channels. Channels are thread safe one way queues. When a thread sends data it transfers ownership of that data to the channel. This guarantees that the sender will never modify the content after sending, thus preventing data races. A receiver can take data from the channel and gain ownership from the queue. After that the receiver is free to use the data in any way it wants.

This technique is similar to unix pipes or Erlangs messaging system. If a channel is empty while trying to receive, the receiver will block. This way of transferring ownership is faster than creating copies of data to be sent over while still guaranteeing data safety. It also relieves the user from having to work with locking or shared memory.

A channel can have multiple senders attached to it. If you want this, you clone the sender as many times as you need it. A channel can have only one receiver. If you need multiple receivers, you will need a mutex. We will come back to that in a minute.

Send and Sync

Not all types can be sent across threads. For instance a non-atomic reference counter cannot be sent because it might introduce a data race. In order to determine what can and what cannot be sent, the so called marker trait Send is automatically derived by the compiler on a type. This happens only when it is composed solely of Send types. A marker trait has no methods, it only exists to mark. A type is Send when it can be moved across threads.

Types that can be shared across threads with a non mutable reference are automatically marked with the Sync trait. Such types often use mutability internally and are not thread safe.

Shared mutable state

In the event that you do need to share mutable data, Rust offers a mutex type. A notable difference with other languages is that in Rust, the proteced data is stored inside the mutex. This makes it impossible to access the data without aqcuiring the lock first. The data is the result of calling the lock() method on a mutex like so. This lock is scoped and released automatically.

We could make our configuration mutable accross theads like so:

fn process_files(worklist: Vec<String>, config: Arc<Mutex<Configuration>>){
	const NTHREADS: usize = 8;

	// Break up the vector in multiple blocks
	let worklists = split_vec_into_chunks(files, NTHREADS);

	let mut thread_handles = vec![];

	for worklist in worklists {
		let config_for_child = config.clone();

		thread_handles.push(
				spawn(move || process_files(worklist, &config_for_child))
				);
	};

	for handle in thread_handles {
		handle.join().unwrap()?;
	}
}

The process files function then accesses the value like so:

let mut config = config_for_child.lock().unwrap();

The mutex is automatically released when the function finishes and its scope ends. Unfortunately, mutexes in Rust do suffer from deadlocks, like any other mutex. One way of getting a deadlock it trying to aqcuire a lock while still within a lock. Rust mutexes are non recursive. Another possibility is to block on multiple mutexes. The linear typesystem cannot protect you from this.

Finally, if a thread panics while holding a lock it will poison the mutex. This means that after that all calls to lock will fail as it may not be safe to use the value within. Rust offers other mechanisms, but we will not look into those further.



8. Unsafe
--------------------

Now that we have seen some of Rusts most prominent safety features, you may wonder how this integrates into the rest of our environment? There is a big corpus of c and c++ code, which includes most operating systems. How can we then interoperate with this world? Welcome to the soft underbelly of the Rust beast... What Rust aims for in terms of safety is to erradicate undefined behavior. In languages like C or C++ there is a notion that the programmer is responsible for checking that writes to an array do not overshoot its boundary, or that we don't use uninitialized memory etc. Rust makes that behavior defined by not allowing it to happen in the first place. The problem we face now is that there are times where we do have to dereference a raw pointer, or perform an unchecked write into an array for the sake of efficiency. An example of reading from and writing to raw pointers would be the glue code we need to interoperate with c/c++ code. We cannot expect the whole world to rewrite everything in Rust, so we need some way to use the code from Rust code. Enter unsafe.

The unsafe keyword does not disable Rusts basic rules. We stil have type checks, lifetime checks, and bounds checks on indices. Inside an unsafe block Rust does allow for some extra features to be enabled on top of that. Some examples are:

- call other unsafe code and implement unsafe traits
- dereference raw pointers
- call functions written in other languages.
- use mutable static variables
- access union fields

The Rust standard library contains numerous pieces of code that are marked unsafe for various reasons. Here is one such example from the Vector code:

pub fn push(&mut self, value: T) {
	// This will panic or abort if we would allocate > isize::MAX bytes
	// or if the length increment would overflow for zero-sized types.
	if self.len == self.buf.capacity() {
		self.reserve(1);
	}
	unsafe {
		let end = self.as_mut_ptr().add(self.len);
		ptr::write(end, value);
		self.len += 1;
	}
}

The push function lets users add a new element to a vector as long as there is still free room. The first part of the function checks if the length is equal to the capacity and reserves more space if it needs to. The second part has been marked unsafe as it dereferences a raw pointer for instance. Here the unsafe keyword tells the compiler that it should trust the author for the correctness of the code. In this case the efficiency of the function was deemed important enough to implement it as an unsafe block to avoid boundary checks. The part that makes is unsafe is the value of end. This is however derived from the self.len value, which in turn is checked in the safe block of this function. In that sense the function is still upholding defined behavior.

That is actually what the unsafe keyword is meant to do: it turns undefined behavior into defined behavior by wrapping unsafe code inside safe code. Now, a caller of the push methog does not need to use the unsafe keyword to call this function. As far as they are concerned, this function is perfectly safe to use.

Unsafe in Rust is a critical part to be able to write efficient code in the standard library, to be able to talk to the operating system and to implement some of the synchronization primitives used for concurrency.

One other thing I would like to mention here is the Rustbelt project. This project aims to perform a formal verification of the Rust standard library and prove it correct.

